{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 파트 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드 및 분할\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train_test_split을 사용하여 학습용 데이터와 테스트 데이터 분할\n",
    "random_state=2024\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링 (선형 회귀에 필요)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.5489\n"
     ]
    }
   ],
   "source": [
    "# 2. 선형 모델 (Linear Regression) 학습 및 예측\n",
    "# TODO: LinearRegression 모델을 생성하고 학습\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled,y_train)\n",
    "\n",
    "# TODO: 학습된 모델로 X_test_scaled를 예측\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# TODO: mean_squared_error 함수를 사용하여 MSE를 계산\n",
    "mse_lr = mean_squared_error(y_test,y_test_pred)\n",
    "\n",
    "print(f\"Linear Regression MSE: {mse_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 0.5457\n"
     ]
    }
   ],
   "source": [
    "# 3. 결정트리 모델 (Decison Tree) 학습 및 예측\n",
    "# TODO: DecisionTreeRegressor 모델을 생성하고 학습\n",
    "model = DecisionTreeRegressor(random_state=random_state)\n",
    "model.fit(X_train,y_train)\n",
    "# TODO: 학습된 모델로 X_test를 예측\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# TODO: mean_squared_error 함수를 사용하여 MSE를 계산\n",
    "mse_dt = mean_squared_error(y_test,y_test_pred)\n",
    "\n",
    "print(f\"Decision Tree MSE: {mse_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.2695\n"
     ]
    }
   ],
   "source": [
    "# 4. 앙상블 모델 (Random Forest) 학습 및 예측\n",
    "# TODO: RandomForestRegressor 모델을 생성하고 학습\n",
    "model = RandomForestRegressor(random_state=random_state)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# TODO: 학습된 모델로 X_test를 예측\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# TODO: mean_squared_error 함수를 사용하여 MSE를 계산\n",
    "mse_rf = mean_squared_error(y_test,y_test_pred)\n",
    "\n",
    "print(f\"Random Forest MSE: {mse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 0.2240\n"
     ]
    }
   ],
   "source": [
    "# 5. 앙상블 모델 (XGBoost) 학습 및 예측\n",
    "# TODO: XGBRegressor 모델을 생성하고 학습\n",
    "model = XGBRegressor(random_state = random_state)\n",
    "model.fit(X_train,y_train)\n",
    "# TODO: 학습된 모델로 X_test를 예측\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# TODO: mean_squared_error 함수를 사용하여 MSE를 계산\n",
    "mse_xgb = mean_squared_error(y_test,y_test_pred)\n",
    "\n",
    "print(f\"XGBoost MSE: {mse_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "               Model       MSE\n",
      "0  Linear Regression  0.548923\n",
      "1      Decision Tree  0.545742\n",
      "2      Random Forest  0.269536\n",
      "3            XGBoost  0.223952\n"
     ]
    }
   ],
   "source": [
    "# 모델 비교\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],\n",
    "    'MSE': [mse_lr, mse_dt, mse_rf, mse_xgb]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드와 데이터에 대한 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터에 대한 간단한 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "california housing prices 데이터셋은 캘리포니아 주를 20640개 구역으로 나눈 후 구역별로 주택 특징과 주택 가격을 조사한 자료이다.\n",
    "\n",
    "attribute는 다음과 같이 8개가 있다.\n",
    "- MedInc: 해당 구역의 수입의 중위값\n",
    "- HouseAge: 해당 구역의 주택 연식의 중위값\n",
    "- AveRooms: 방 개수 평균\n",
    "- AveBedrms: 침실 개수 평균\n",
    "- Population: 해당 구역의 인구 수\n",
    "- AveOccup: : 평균 가구 구성원 수\n",
    "- Latitude: 해당 블록의 위도\n",
    "- Longitude: 해당 블록의 경도\n",
    "\n",
    "target은 해당 구역의 집값의 중위값으로, $100,000 달러 단위이다.\n",
    "\n",
    "따라서 feature는 (26480,8), target은 (26480,) 의 shape를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 모델에 대한 간단한 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear Regression\n",
    "\n",
    "종속 변수와 하나 이상의 독립 변수 간의 선형 관계를 찾고, 최적의 직선을 찾는다. 최적의 직선이 $y=b_0 + b_1x_1+b_2x_2 + ... + b_nx_n$ 이고, 독립변수 $X$와 종속변수 벡터 $y$에 대해 $b$는 다음과 같이 구할 수 있다.\n",
    "\n",
    "$$ b = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "2. Decision Tree\n",
    "\n",
    "루트 노드에서부터 시작하여 리프노드까지 데이터를 여러 기준에 따라 분리하고(불순도가 낮아지게 분리함), 리프노드에서 최종적으로 결과를 예측한다.\n",
    "\n",
    "3. Random Forest\n",
    "\n",
    "무작위로 데이터를 샘플링하고, feature를 고르는 것을 여러 번 반복하여 Tree 모델을 여러개 만들고, 각 모델의 예측 값을 평균 또는 투표를 통해 최종 값을 예측한다.\n",
    "\n",
    "4. XGBoost\n",
    "\n",
    "트리 모델을 여러 개 만들면서 이전 단계에서 잘 예측하지 못했던 instance에 가중치를 가하여 학습하면서 오차를 줄여나간다. 또한 모델의 복잡성에 대해 패널티를 추가하여 일반화 성능을 높인다.\n",
    "\n",
    "$$ obj(\\theta) = \\sum_i^n l(y_i,\\hat y_i) + \\sum_{k=1}^K \\omega(f_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 간 성능 차이와 그 이유에 대한 논의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression과 Decision Tree 모델 보다 Random Forest와 XGBoost 모델의 test error가 더 낮다. 이는 Random Forest와 XGBoost가 Linear Regression과 Decision Tree보다 데이터의 보편적인 특성을 잘 학습한다는 의미이다. 이는 Linear Regression과 Decision Tree는 하나의 모델만 만들며, 모든 훈련 데이터셋과 모든 feature를 사용하기 때문에, 훈련 데이터셋에 과적합될 수 있다(Decision Tree에서는 트리 깊이나 리프 노드의 개수의 상한선을 결정하여 이를 어느정도 방지할 수는 있다.).\n",
    "\n",
    "그러나 Random Forest와 XGBoost에서는 모델을 여러 개 만들어 해당 모델의 다수 또는 평균을 최종 출력하기 때문에, 특정 데이터에 과적합되는 것을 방지할 수 있고, 따라서 테스트 데이터셋에 대해 MSE가 더 낮다. 또한 XGBoost는 이전 모델이 잘 예측하지 못했던 데이터에 대해 가중치를 주어 학습하고, 큰 가중치에 패널티를 주어 학습하므로 XGBoost의 에러율이 가장 낮을 것을 알 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
